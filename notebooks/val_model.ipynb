{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.binary_dataloader import BinaryLoader\n",
    "from utils.train_validation_split import random_train_val_split\n",
    "from utils.metrics_evaluator import PerformanceMetricsEvaluator\n",
    "from models.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mask_functions import better_mask2rle, rle2mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose free GPU\n",
    "device = \"cpu\"\n",
    "\n",
    "ROOT_DIR = 'data/processed/'\n",
    "DIR_TO_CSV = 'data/raw/train-rle.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "csv_file = pd.read_csv(DIR_TO_CSV)\n",
    "train_csv, val_csv = random_train_val_split(csv_file, 0.2, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = BinaryLoader(val_csv, ROOT_DIR)\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "model = UNet((3,512,512))\n",
    "model.load_state_dict(torch.load(\"weights/unet_baseline_weighted_crossentropy0.233407.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(img, gt, *args):\n",
    "    length = len(args) + 2\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(1, length, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, length, 2)\n",
    "    plt.imshow(gt)\n",
    "    for i, el in enumerate(args):\n",
    "        plt.subplot(1, length, i+3)\n",
    "        plt.imshow(el)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def viz_val_set():\n",
    "    for imgs, masks in tqdm(val_loader):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        masks = masks[0]\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs)\n",
    "        imgs = imgs.numpy()[0].transpose((1, 2, 0))\n",
    "        logits = logits.softmax(dim=1).argmax(dim=1)\n",
    "        logits = logits.numpy().reshape((1, 128, 128))\n",
    "        preview(imgs, masks, logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pre_submit(in_dir, out_dir):\n",
    "    for img_fn in tqdm(os.listdir(in_dir)):\n",
    "        img_path = os.path.join(in_dir, img_fn)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#         img = cv2.resize(img, (256, 256))\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        img = torch.tensor([img.transpose(2, 0, 1)], dtype=torch.float32)\n",
    "        imgs = img.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs)\n",
    "        imgs = imgs.numpy()[0].transpose((1, 2, 0))\n",
    "        logits = logits.softmax(dim=1).argmax(dim=1)\n",
    "        logits = (logits.numpy().reshape((1, 128, 128))[0])#.astype(np.float32)\n",
    "        out = cv2.resize(logits, (1024, 1024), interpolation=cv2.INTER_NEAREST)#.astype(np.uint8)\n",
    "#         plt.imshow(out), plt.show()\n",
    "        out = measure.label(out, background=0)\n",
    "        cv2.imwrite(os.path.join(out_dir, img_fn), out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, masks in tqdm(val_loader):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        masks = masks[0]\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs)\n",
    "        imgs = imgs.numpy()[0].transpose((1, 2, 0))\n",
    "        logits = logits.softmax(dim=1).argmax(dim=1)\n",
    "        logits = logits.numpy().reshape((1, 128, 128))\n",
    "        preview(imgs, masks, logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz_val_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_mapping import dcm2png\n",
    "import os\n",
    "import cv2\n",
    "from skimage import measure\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"data/pre_out\")\n",
    "os.mkdir(\"data/pre_out\")\n",
    "dcm2png(\"data/raw/dicom-images-test/\", \"data/pre_out/\", v=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"data/out\")\n",
    "os.mkdir(\"data/out\")\n",
    "create_pre_submit(\"data/pre_out\", \"data/out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.make_submission import create_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1377 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: 1377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1377/1377 [10:59<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission is saved to submission_baseline.csv successfully!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_submission('data/out', 'baseline', v=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = list(test_img.T.reshape(-1))\n",
    "start = 0\n",
    "data = []\n",
    "prev = 0\n",
    "for val, lst in groupby(flat):\n",
    "    length = len(list(lst))\n",
    "    if val > 0:\n",
    "        data.append(prev)\n",
    "        data.append(length)\n",
    "    prev = length\n",
    "    start += length\n",
    "if len(data) == 0:\n",
    "    print(\"-1\")\n",
    "res = \" \".join(map(str, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mask_functions import mask2rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mask2rle(test_img*255, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 128\n",
    "rle = res\n",
    "mask= np.zeros(width* height)\n",
    "array = np.asarray([int(x) for x in rle.split()])\n",
    "starts = array[0::2]\n",
    "lengths = array[1::2]\n",
    "\n",
    "current_position = 0\n",
    "for index, start in enumerate(starts):\n",
    "    current_position += start\n",
    "    mask[current_position:current_position+lengths[index]] = 255\n",
    "    current_position += lengths[index]\n",
    "mask = mask.reshape(width, height)\n",
    "plt.imshow(mask), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
